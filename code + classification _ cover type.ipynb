{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.8"
    },
    "colab": {
      "name": "classifivation_project_moham_sa.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "VA-G3ZYh5yMe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "178437d6-9864-45ba-efb8-c089500b9bce"
      },
      "source": [
        "%pip install datapackage\n",
        "import datapackage\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from pandas.api.types import is_numeric_dtype\n",
        "import numpy as np\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "data_url = 'https://datahub.io/machine-learning/covertype/datapackage.json'\n",
        "\n",
        "# to load Data Package into storage\n",
        "package = datapackage.Package(data_url)\n",
        "\n",
        "# to load only tabular data\n",
        "resources = package.resources\n",
        "for resource in resources:\n",
        "    if resource.tabular:\n",
        "        data = pd.read_csv(resource.descriptor['path'])\n",
        "        print (data)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datapackage in /usr/local/lib/python3.7/dist-packages (1.15.2)\n",
            "Requirement already satisfied: jsonschema>=2.5 in /usr/local/lib/python3.7/dist-packages (from datapackage) (2.6.0)\n",
            "Requirement already satisfied: click>=6.7 in /usr/local/lib/python3.7/dist-packages (from datapackage) (7.1.2)\n",
            "Requirement already satisfied: tableschema>=1.12.1 in /usr/local/lib/python3.7/dist-packages (from datapackage) (1.20.2)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from datapackage) (1.15.0)\n",
            "Requirement already satisfied: unicodecsv>=0.14 in /usr/local/lib/python3.7/dist-packages (from datapackage) (0.14.1)\n",
            "Requirement already satisfied: tabulator>=1.29 in /usr/local/lib/python3.7/dist-packages (from datapackage) (1.53.5)\n",
            "Requirement already satisfied: jsonpointer>=1.10 in /usr/local/lib/python3.7/dist-packages (from datapackage) (2.2)\n",
            "Requirement already satisfied: requests>=2.8 in /usr/local/lib/python3.7/dist-packages (from datapackage) (2.23.0)\n",
            "Requirement already satisfied: chardet>=3.0 in /usr/local/lib/python3.7/dist-packages (from datapackage) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.8->datapackage) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.8->datapackage) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.8->datapackage) (1.25.11)\n",
            "Requirement already satisfied: isodate>=0.5.4 in /usr/local/lib/python3.7/dist-packages (from tableschema>=1.12.1->datapackage) (0.6.0)\n",
            "Requirement already satisfied: rfc3986>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tableschema>=1.12.1->datapackage) (1.5.0)\n",
            "Requirement already satisfied: cached-property>=1.5 in /usr/local/lib/python3.7/dist-packages (from tableschema>=1.12.1->datapackage) (1.5.2)\n",
            "Requirement already satisfied: python-dateutil>=2.4 in /usr/local/lib/python3.7/dist-packages (from tableschema>=1.12.1->datapackage) (2.8.2)\n",
            "Requirement already satisfied: jsonlines>=1.1 in /usr/local/lib/python3.7/dist-packages (from tabulator>=1.29->datapackage) (2.0.0)\n",
            "Requirement already satisfied: ijson>=3.0.3 in /usr/local/lib/python3.7/dist-packages (from tabulator>=1.29->datapackage) (3.1.4)\n",
            "Requirement already satisfied: sqlalchemy>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from tabulator>=1.29->datapackage) (1.4.26)\n",
            "Requirement already satisfied: openpyxl>=2.6 in /usr/local/lib/python3.7/dist-packages (from tabulator>=1.29->datapackage) (3.0.9)\n",
            "Requirement already satisfied: linear-tsv>=1.0 in /usr/local/lib/python3.7/dist-packages (from tabulator>=1.29->datapackage) (1.1.0)\n",
            "Requirement already satisfied: boto3>=1.9 in /usr/local/lib/python3.7/dist-packages (from tabulator>=1.29->datapackage) (1.20.7)\n",
            "Requirement already satisfied: xlrd>=1.0 in /usr/local/lib/python3.7/dist-packages (from tabulator>=1.29->datapackage) (1.1.0)\n",
            "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from boto3>=1.9->tabulator>=1.29->datapackage) (0.5.0)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3>=1.9->tabulator>=1.29->datapackage) (0.10.0)\n",
            "Requirement already satisfied: botocore<1.24.0,>=1.23.7 in /usr/local/lib/python3.7/dist-packages (from boto3>=1.9->tabulator>=1.29->datapackage) (1.23.7)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.7/dist-packages (from openpyxl>=2.6->tabulator>=1.29->datapackage) (1.1.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=0.9.6->tabulator>=1.29->datapackage) (1.1.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=0.9.6->tabulator>=1.29->datapackage) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy>=0.9.6->tabulator>=1.29->datapackage) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy>=0.9.6->tabulator>=1.29->datapackage) (3.10.0.2)\n",
            "        Elevation    Aspect     Slope  ...  Soil_Type39  Soil_Type40  class\n",
            "0        0.368684  0.141667  0.045455  ...            0            0      5\n",
            "1        0.365683  0.155556  0.030303  ...            0            0      5\n",
            "2        0.472736  0.386111  0.136364  ...            0            0      2\n",
            "3        0.463232  0.430556  0.272727  ...            0            0      2\n",
            "4        0.368184  0.125000  0.030303  ...            0            0      5\n",
            "...           ...       ...       ...  ...          ...          ...    ...\n",
            "581007   0.268634  0.425000  0.303030  ...            0            0      3\n",
            "581008   0.266133  0.422222  0.287879  ...            0            0      3\n",
            "581009   0.263632  0.441667  0.257576  ...            0            0      3\n",
            "581010   0.262631  0.472222  0.227273  ...            0            0      3\n",
            "581011   0.262131  0.458333  0.196970  ...            0            0      3\n",
            "\n",
            "[581012 rows x 55 columns]\n",
            "        Elevation    Aspect     Slope  ...  Soil_Type39  Soil_Type40  class\n",
            "0        0.368684  0.141667  0.045455  ...            0            0      5\n",
            "1        0.365683  0.155556  0.030303  ...            0            0      5\n",
            "2        0.472736  0.386111  0.136364  ...            0            0      2\n",
            "3        0.463232  0.430556  0.272727  ...            0            0      2\n",
            "4        0.368184  0.125000  0.030303  ...            0            0      5\n",
            "...           ...       ...       ...  ...          ...          ...    ...\n",
            "581007   0.268634  0.425000  0.303030  ...            0            0      3\n",
            "581008   0.266133  0.422222  0.287879  ...            0            0      3\n",
            "581009   0.263632  0.441667  0.257576  ...            0            0      3\n",
            "581010   0.262631  0.472222  0.227273  ...            0            0      3\n",
            "581011   0.262131  0.458333  0.196970  ...            0            0      3\n",
            "\n",
            "[581012 rows x 55 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZZ5IsaO5yMu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "outputId": "97ff17f0-8f86-42a5-ab37-926dfc87f549"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Elevation</th>\n",
              "      <th>Aspect</th>\n",
              "      <th>Slope</th>\n",
              "      <th>Horizontal_Distance_To_Hydrology</th>\n",
              "      <th>Vertical_Distance_To_Hydrology</th>\n",
              "      <th>Horizontal_Distance_To_Roadways</th>\n",
              "      <th>Hillshade_9am</th>\n",
              "      <th>Hillshade_Noon</th>\n",
              "      <th>Hillshade_3pm</th>\n",
              "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
              "      <th>Wilderness_Area1</th>\n",
              "      <th>Wilderness_Area2</th>\n",
              "      <th>Wilderness_Area3</th>\n",
              "      <th>Wilderness_Area4</th>\n",
              "      <th>Soil_Type1</th>\n",
              "      <th>Soil_Type2</th>\n",
              "      <th>Soil_Type3</th>\n",
              "      <th>Soil_Type4</th>\n",
              "      <th>Soil_Type5</th>\n",
              "      <th>Soil_Type6</th>\n",
              "      <th>Soil_Type7</th>\n",
              "      <th>Soil_Type8</th>\n",
              "      <th>Soil_Type9</th>\n",
              "      <th>Soil_Type10</th>\n",
              "      <th>Soil_Type11</th>\n",
              "      <th>Soil_Type12</th>\n",
              "      <th>Soil_Type13</th>\n",
              "      <th>Soil_Type14</th>\n",
              "      <th>Soil_Type15</th>\n",
              "      <th>Soil_Type16</th>\n",
              "      <th>Soil_Type17</th>\n",
              "      <th>Soil_Type18</th>\n",
              "      <th>Soil_Type19</th>\n",
              "      <th>Soil_Type20</th>\n",
              "      <th>Soil_Type21</th>\n",
              "      <th>Soil_Type22</th>\n",
              "      <th>Soil_Type23</th>\n",
              "      <th>Soil_Type24</th>\n",
              "      <th>Soil_Type25</th>\n",
              "      <th>Soil_Type26</th>\n",
              "      <th>Soil_Type27</th>\n",
              "      <th>Soil_Type28</th>\n",
              "      <th>Soil_Type29</th>\n",
              "      <th>Soil_Type30</th>\n",
              "      <th>Soil_Type31</th>\n",
              "      <th>Soil_Type32</th>\n",
              "      <th>Soil_Type33</th>\n",
              "      <th>Soil_Type34</th>\n",
              "      <th>Soil_Type35</th>\n",
              "      <th>Soil_Type36</th>\n",
              "      <th>Soil_Type37</th>\n",
              "      <th>Soil_Type38</th>\n",
              "      <th>Soil_Type39</th>\n",
              "      <th>Soil_Type40</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.368684</td>\n",
              "      <td>0.141667</td>\n",
              "      <td>0.045455</td>\n",
              "      <td>0.184681</td>\n",
              "      <td>0.223514</td>\n",
              "      <td>0.071659</td>\n",
              "      <td>0.870079</td>\n",
              "      <td>0.913386</td>\n",
              "      <td>0.582677</td>\n",
              "      <td>0.875366</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.365683</td>\n",
              "      <td>0.155556</td>\n",
              "      <td>0.030303</td>\n",
              "      <td>0.151754</td>\n",
              "      <td>0.215762</td>\n",
              "      <td>0.054798</td>\n",
              "      <td>0.866142</td>\n",
              "      <td>0.925197</td>\n",
              "      <td>0.594488</td>\n",
              "      <td>0.867838</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.472736</td>\n",
              "      <td>0.386111</td>\n",
              "      <td>0.136364</td>\n",
              "      <td>0.191840</td>\n",
              "      <td>0.307494</td>\n",
              "      <td>0.446817</td>\n",
              "      <td>0.921260</td>\n",
              "      <td>0.937008</td>\n",
              "      <td>0.531496</td>\n",
              "      <td>0.853339</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.463232</td>\n",
              "      <td>0.430556</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>0.173228</td>\n",
              "      <td>0.375969</td>\n",
              "      <td>0.434172</td>\n",
              "      <td>0.937008</td>\n",
              "      <td>0.937008</td>\n",
              "      <td>0.480315</td>\n",
              "      <td>0.865886</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.368184</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.030303</td>\n",
              "      <td>0.109520</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.054939</td>\n",
              "      <td>0.866142</td>\n",
              "      <td>0.921260</td>\n",
              "      <td>0.590551</td>\n",
              "      <td>0.860449</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Elevation    Aspect     Slope  ...  Soil_Type39  Soil_Type40  class\n",
              "0   0.368684  0.141667  0.045455  ...            0            0      5\n",
              "1   0.365683  0.155556  0.030303  ...            0            0      5\n",
              "2   0.472736  0.386111  0.136364  ...            0            0      2\n",
              "3   0.463232  0.430556  0.272727  ...            0            0      2\n",
              "4   0.368184  0.125000  0.030303  ...            0            0      5\n",
              "\n",
              "[5 rows x 55 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwLrssnM5yM2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96bf79e3-793b-494c-d525-bd29e5497442"
      },
      "source": [
        "#--------------------------------\n",
        "\n",
        "\n",
        "# row mean instance\n",
        "# columns mean attributes\n",
        "print(data.shape)\n",
        "print('Number of instances = %d' % (data.shape[0]))\n",
        "print('Number of attributes = %d' % (data.shape[1]))\n",
        "# willl print (instances , attributes)\n",
        "\n",
        "\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(581012, 55)\n",
            "Number of instances = 581012\n",
            "Number of attributes = 55\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-J11OrWq5yM_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "623138bf-04cd-4951-d0a4-1707bac231ae"
      },
      "source": [
        "#--------------------------------\n",
        "\n",
        "# . For each class label, display the code of the class label and the\n",
        "# name of that class.\n",
        "print(data['class'].value_counts())\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2    283301\n",
            "1    211840\n",
            "3     35754\n",
            "7     20510\n",
            "6     17367\n",
            "5      9493\n",
            "4      2747\n",
            "Name: class, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80XYtzU_5yNG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "a91d98dc-769f-44fd-e10e-a6a4bda3d6bf"
      },
      "source": [
        "#--------------------------------\n",
        "\n",
        "# Summarise the class distribution using a suitable graph.\n",
        "cls = data['class'].astype('object').value_counts()\n",
        "\n",
        "plt.bar(cls.index, cls)\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJ31-5mP5yNQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "outputId": "74c897b0-0c76-4e6f-afe1-a4379c8befe1"
      },
      "source": [
        "#--------------------------------\n",
        "\n",
        "# Display a statistical summary for all the attributes.\n",
        "# for col in data.columns:\n",
        "\n",
        "#     if is_numeric_dtype(data[col]):\n",
        "#         print('%s:' % (col))\n",
        "#         print('\\t Mean = %.2f' % data[col].mean())\n",
        "#         print('\\t Standard deviation = %.2f' % data[col].std())\n",
        "#         print('\\t Minimum = %.2f' % data[col].min())\n",
        "#         print('\\t Maximum = %.2f' % data[col].max())\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "df.describe()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Elevation</th>\n",
              "      <th>Aspect</th>\n",
              "      <th>Slope</th>\n",
              "      <th>Horizontal_Distance_To_Hydrology</th>\n",
              "      <th>Vertical_Distance_To_Hydrology</th>\n",
              "      <th>Horizontal_Distance_To_Roadways</th>\n",
              "      <th>Hillshade_9am</th>\n",
              "      <th>Hillshade_Noon</th>\n",
              "      <th>Hillshade_3pm</th>\n",
              "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
              "      <th>Wilderness_Area1</th>\n",
              "      <th>Wilderness_Area2</th>\n",
              "      <th>Wilderness_Area3</th>\n",
              "      <th>Wilderness_Area4</th>\n",
              "      <th>Soil_Type1</th>\n",
              "      <th>Soil_Type2</th>\n",
              "      <th>Soil_Type3</th>\n",
              "      <th>Soil_Type4</th>\n",
              "      <th>Soil_Type5</th>\n",
              "      <th>Soil_Type6</th>\n",
              "      <th>Soil_Type7</th>\n",
              "      <th>Soil_Type8</th>\n",
              "      <th>Soil_Type9</th>\n",
              "      <th>Soil_Type10</th>\n",
              "      <th>Soil_Type11</th>\n",
              "      <th>Soil_Type12</th>\n",
              "      <th>Soil_Type13</th>\n",
              "      <th>Soil_Type14</th>\n",
              "      <th>Soil_Type15</th>\n",
              "      <th>Soil_Type16</th>\n",
              "      <th>Soil_Type17</th>\n",
              "      <th>Soil_Type18</th>\n",
              "      <th>Soil_Type19</th>\n",
              "      <th>Soil_Type20</th>\n",
              "      <th>Soil_Type21</th>\n",
              "      <th>Soil_Type22</th>\n",
              "      <th>Soil_Type23</th>\n",
              "      <th>Soil_Type24</th>\n",
              "      <th>Soil_Type25</th>\n",
              "      <th>Soil_Type26</th>\n",
              "      <th>Soil_Type27</th>\n",
              "      <th>Soil_Type28</th>\n",
              "      <th>Soil_Type29</th>\n",
              "      <th>Soil_Type30</th>\n",
              "      <th>Soil_Type31</th>\n",
              "      <th>Soil_Type32</th>\n",
              "      <th>Soil_Type33</th>\n",
              "      <th>Soil_Type34</th>\n",
              "      <th>Soil_Type35</th>\n",
              "      <th>Soil_Type36</th>\n",
              "      <th>Soil_Type37</th>\n",
              "      <th>Soil_Type38</th>\n",
              "      <th>Soil_Type39</th>\n",
              "      <th>Soil_Type40</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.550458</td>\n",
              "      <td>0.432380</td>\n",
              "      <td>0.213693</td>\n",
              "      <td>0.192862</td>\n",
              "      <td>0.283487</td>\n",
              "      <td>0.330216</td>\n",
              "      <td>0.835221</td>\n",
              "      <td>0.879208</td>\n",
              "      <td>0.561135</td>\n",
              "      <td>0.276076</td>\n",
              "      <td>0.448865</td>\n",
              "      <td>0.051434</td>\n",
              "      <td>0.436074</td>\n",
              "      <td>0.063627</td>\n",
              "      <td>0.005217</td>\n",
              "      <td>0.012952</td>\n",
              "      <td>0.008301</td>\n",
              "      <td>0.021335</td>\n",
              "      <td>0.002749</td>\n",
              "      <td>0.011316</td>\n",
              "      <td>0.000181</td>\n",
              "      <td>0.000308</td>\n",
              "      <td>0.001974</td>\n",
              "      <td>0.056168</td>\n",
              "      <td>0.021359</td>\n",
              "      <td>0.051584</td>\n",
              "      <td>0.030001</td>\n",
              "      <td>0.001031</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>0.004897</td>\n",
              "      <td>0.005890</td>\n",
              "      <td>0.003268</td>\n",
              "      <td>0.006921</td>\n",
              "      <td>0.015936</td>\n",
              "      <td>0.001442</td>\n",
              "      <td>0.057439</td>\n",
              "      <td>0.099399</td>\n",
              "      <td>0.036622</td>\n",
              "      <td>0.000816</td>\n",
              "      <td>0.004456</td>\n",
              "      <td>0.001869</td>\n",
              "      <td>0.001628</td>\n",
              "      <td>0.198356</td>\n",
              "      <td>0.051927</td>\n",
              "      <td>0.044175</td>\n",
              "      <td>0.090392</td>\n",
              "      <td>0.077716</td>\n",
              "      <td>0.002773</td>\n",
              "      <td>0.003255</td>\n",
              "      <td>0.000205</td>\n",
              "      <td>0.000513</td>\n",
              "      <td>0.026803</td>\n",
              "      <td>0.023762</td>\n",
              "      <td>0.015060</td>\n",
              "      <td>2.051471</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.140062</td>\n",
              "      <td>0.310871</td>\n",
              "      <td>0.113458</td>\n",
              "      <td>0.152147</td>\n",
              "      <td>0.075317</td>\n",
              "      <td>0.219089</td>\n",
              "      <td>0.105393</td>\n",
              "      <td>0.077830</td>\n",
              "      <td>0.150687</td>\n",
              "      <td>0.184608</td>\n",
              "      <td>0.497379</td>\n",
              "      <td>0.220882</td>\n",
              "      <td>0.495897</td>\n",
              "      <td>0.244087</td>\n",
              "      <td>0.072039</td>\n",
              "      <td>0.113066</td>\n",
              "      <td>0.090731</td>\n",
              "      <td>0.144499</td>\n",
              "      <td>0.052356</td>\n",
              "      <td>0.105775</td>\n",
              "      <td>0.013442</td>\n",
              "      <td>0.017550</td>\n",
              "      <td>0.044387</td>\n",
              "      <td>0.230245</td>\n",
              "      <td>0.144579</td>\n",
              "      <td>0.221186</td>\n",
              "      <td>0.170590</td>\n",
              "      <td>0.032092</td>\n",
              "      <td>0.002272</td>\n",
              "      <td>0.069804</td>\n",
              "      <td>0.076518</td>\n",
              "      <td>0.057077</td>\n",
              "      <td>0.082902</td>\n",
              "      <td>0.125228</td>\n",
              "      <td>0.037950</td>\n",
              "      <td>0.232681</td>\n",
              "      <td>0.299197</td>\n",
              "      <td>0.187833</td>\n",
              "      <td>0.028551</td>\n",
              "      <td>0.066605</td>\n",
              "      <td>0.043193</td>\n",
              "      <td>0.040318</td>\n",
              "      <td>0.398762</td>\n",
              "      <td>0.221879</td>\n",
              "      <td>0.205483</td>\n",
              "      <td>0.286743</td>\n",
              "      <td>0.267725</td>\n",
              "      <td>0.052584</td>\n",
              "      <td>0.056957</td>\n",
              "      <td>0.014310</td>\n",
              "      <td>0.022641</td>\n",
              "      <td>0.161508</td>\n",
              "      <td>0.152307</td>\n",
              "      <td>0.121791</td>\n",
              "      <td>1.396504</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.475238</td>\n",
              "      <td>0.161111</td>\n",
              "      <td>0.136364</td>\n",
              "      <td>0.077309</td>\n",
              "      <td>0.232558</td>\n",
              "      <td>0.155403</td>\n",
              "      <td>0.779528</td>\n",
              "      <td>0.838583</td>\n",
              "      <td>0.468504</td>\n",
              "      <td>0.142758</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.568784</td>\n",
              "      <td>0.352778</td>\n",
              "      <td>0.196970</td>\n",
              "      <td>0.156049</td>\n",
              "      <td>0.262274</td>\n",
              "      <td>0.280596</td>\n",
              "      <td>0.858268</td>\n",
              "      <td>0.889764</td>\n",
              "      <td>0.562992</td>\n",
              "      <td>0.238394</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.652326</td>\n",
              "      <td>0.722222</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>0.274875</td>\n",
              "      <td>0.312661</td>\n",
              "      <td>0.467613</td>\n",
              "      <td>0.909449</td>\n",
              "      <td>0.933071</td>\n",
              "      <td>0.661417</td>\n",
              "      <td>0.355500</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>7.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Elevation         Aspect  ...    Soil_Type40          class\n",
              "count  581012.000000  581012.000000  ...  581012.000000  581012.000000\n",
              "mean        0.550458       0.432380  ...       0.015060       2.051471\n",
              "std         0.140062       0.310871  ...       0.121791       1.396504\n",
              "min         0.000000       0.000000  ...       0.000000       1.000000\n",
              "25%         0.475238       0.161111  ...       0.000000       1.000000\n",
              "50%         0.568784       0.352778  ...       0.000000       2.000000\n",
              "75%         0.652326       0.722222  ...       0.000000       2.000000\n",
              "max         1.000000       1.000000  ...       1.000000       7.000000\n",
              "\n",
              "[8 rows x 55 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XibaxSth5yNa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9eaf4b42-57e4-49d9-85d6-0ff65e43781a"
      },
      "source": [
        "#--------------------------------\n",
        "\n",
        "# Check whether the selected dataset has any data quality issues\n",
        "# and choose suitable strategies to deal with any issue (if exists).\n",
        "data = data.replace('?',np.NaN)\n",
        "\n",
        "print('Number of instances = %d' % (data.shape[0]))\n",
        "print('Number of attributes = %d' % (data.shape[1]))\n",
        "\n",
        "print('Number of missing values:')\n",
        "for col in data.columns:\n",
        "    print('\\t%s: %d' % (col,data[col].isna().sum()))\n",
        "# as we can see no data missing\n",
        "\n",
        "# lets check duplicated data\n",
        "dups = data.duplicated()\n",
        "print('Number of duplicate rows = %d' % (dups.sum()))\n",
        "\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of instances = 581012\n",
            "Number of attributes = 55\n",
            "Number of missing values:\n",
            "\tElevation: 0\n",
            "\tAspect: 0\n",
            "\tSlope: 0\n",
            "\tHorizontal_Distance_To_Hydrology: 0\n",
            "\tVertical_Distance_To_Hydrology: 0\n",
            "\tHorizontal_Distance_To_Roadways: 0\n",
            "\tHillshade_9am: 0\n",
            "\tHillshade_Noon: 0\n",
            "\tHillshade_3pm: 0\n",
            "\tHorizontal_Distance_To_Fire_Points: 0\n",
            "\tWilderness_Area1: 0\n",
            "\tWilderness_Area2: 0\n",
            "\tWilderness_Area3: 0\n",
            "\tWilderness_Area4: 0\n",
            "\tSoil_Type1: 0\n",
            "\tSoil_Type2: 0\n",
            "\tSoil_Type3: 0\n",
            "\tSoil_Type4: 0\n",
            "\tSoil_Type5: 0\n",
            "\tSoil_Type6: 0\n",
            "\tSoil_Type7: 0\n",
            "\tSoil_Type8: 0\n",
            "\tSoil_Type9: 0\n",
            "\tSoil_Type10: 0\n",
            "\tSoil_Type11: 0\n",
            "\tSoil_Type12: 0\n",
            "\tSoil_Type13: 0\n",
            "\tSoil_Type14: 0\n",
            "\tSoil_Type15: 0\n",
            "\tSoil_Type16: 0\n",
            "\tSoil_Type17: 0\n",
            "\tSoil_Type18: 0\n",
            "\tSoil_Type19: 0\n",
            "\tSoil_Type20: 0\n",
            "\tSoil_Type21: 0\n",
            "\tSoil_Type22: 0\n",
            "\tSoil_Type23: 0\n",
            "\tSoil_Type24: 0\n",
            "\tSoil_Type25: 0\n",
            "\tSoil_Type26: 0\n",
            "\tSoil_Type27: 0\n",
            "\tSoil_Type28: 0\n",
            "\tSoil_Type29: 0\n",
            "\tSoil_Type30: 0\n",
            "\tSoil_Type31: 0\n",
            "\tSoil_Type32: 0\n",
            "\tSoil_Type33: 0\n",
            "\tSoil_Type34: 0\n",
            "\tSoil_Type35: 0\n",
            "\tSoil_Type36: 0\n",
            "\tSoil_Type37: 0\n",
            "\tSoil_Type38: 0\n",
            "\tSoil_Type39: 0\n",
            "\tSoil_Type40: 0\n",
            "\tclass: 0\n",
            "Number of duplicate rows = 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxtvUQV_8oDk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "321e97da-554e-4bb6-8033-932f2d66815e"
      },
      "source": [
        "data.info()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 581012 entries, 0 to 581011\n",
            "Data columns (total 55 columns):\n",
            " #   Column                              Non-Null Count   Dtype  \n",
            "---  ------                              --------------   -----  \n",
            " 0   Elevation                           581012 non-null  float64\n",
            " 1   Aspect                              581012 non-null  float64\n",
            " 2   Slope                               581012 non-null  float64\n",
            " 3   Horizontal_Distance_To_Hydrology    581012 non-null  float64\n",
            " 4   Vertical_Distance_To_Hydrology      581012 non-null  float64\n",
            " 5   Horizontal_Distance_To_Roadways     581012 non-null  float64\n",
            " 6   Hillshade_9am                       581012 non-null  float64\n",
            " 7   Hillshade_Noon                      581012 non-null  float64\n",
            " 8   Hillshade_3pm                       581012 non-null  float64\n",
            " 9   Horizontal_Distance_To_Fire_Points  581012 non-null  float64\n",
            " 10  Wilderness_Area1                    581012 non-null  int64  \n",
            " 11  Wilderness_Area2                    581012 non-null  int64  \n",
            " 12  Wilderness_Area3                    581012 non-null  int64  \n",
            " 13  Wilderness_Area4                    581012 non-null  int64  \n",
            " 14  Soil_Type1                          581012 non-null  int64  \n",
            " 15  Soil_Type2                          581012 non-null  int64  \n",
            " 16  Soil_Type3                          581012 non-null  int64  \n",
            " 17  Soil_Type4                          581012 non-null  int64  \n",
            " 18  Soil_Type5                          581012 non-null  int64  \n",
            " 19  Soil_Type6                          581012 non-null  int64  \n",
            " 20  Soil_Type7                          581012 non-null  int64  \n",
            " 21  Soil_Type8                          581012 non-null  int64  \n",
            " 22  Soil_Type9                          581012 non-null  int64  \n",
            " 23  Soil_Type10                         581012 non-null  int64  \n",
            " 24  Soil_Type11                         581012 non-null  int64  \n",
            " 25  Soil_Type12                         581012 non-null  int64  \n",
            " 26  Soil_Type13                         581012 non-null  int64  \n",
            " 27  Soil_Type14                         581012 non-null  int64  \n",
            " 28  Soil_Type15                         581012 non-null  int64  \n",
            " 29  Soil_Type16                         581012 non-null  int64  \n",
            " 30  Soil_Type17                         581012 non-null  int64  \n",
            " 31  Soil_Type18                         581012 non-null  int64  \n",
            " 32  Soil_Type19                         581012 non-null  int64  \n",
            " 33  Soil_Type20                         581012 non-null  int64  \n",
            " 34  Soil_Type21                         581012 non-null  int64  \n",
            " 35  Soil_Type22                         581012 non-null  int64  \n",
            " 36  Soil_Type23                         581012 non-null  int64  \n",
            " 37  Soil_Type24                         581012 non-null  int64  \n",
            " 38  Soil_Type25                         581012 non-null  int64  \n",
            " 39  Soil_Type26                         581012 non-null  int64  \n",
            " 40  Soil_Type27                         581012 non-null  int64  \n",
            " 41  Soil_Type28                         581012 non-null  int64  \n",
            " 42  Soil_Type29                         581012 non-null  int64  \n",
            " 43  Soil_Type30                         581012 non-null  int64  \n",
            " 44  Soil_Type31                         581012 non-null  int64  \n",
            " 45  Soil_Type32                         581012 non-null  int64  \n",
            " 46  Soil_Type33                         581012 non-null  int64  \n",
            " 47  Soil_Type34                         581012 non-null  int64  \n",
            " 48  Soil_Type35                         581012 non-null  int64  \n",
            " 49  Soil_Type36                         581012 non-null  int64  \n",
            " 50  Soil_Type37                         581012 non-null  int64  \n",
            " 51  Soil_Type38                         581012 non-null  int64  \n",
            " 52  Soil_Type39                         581012 non-null  int64  \n",
            " 53  Soil_Type40                         581012 non-null  int64  \n",
            " 54  class                               581012 non-null  int64  \n",
            "dtypes: float64(10), int64(45)\n",
            "memory usage: 243.8 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cerfpYL_5yNp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50bf0259-ad81-4bcd-e2a1-6fd399dbca37"
      },
      "source": [
        "#--------------------------------\n",
        "#Convert the multiclass classification problem into a binary\n",
        "#classification problem.\n",
        "print('Before converting: \\n',data['class'].value_counts() )\n",
        "data['class'] = data['class'].replace([1,3,4,5,6,7],0)\n",
        "data['class'] = data['class'].replace([2],1) # Class with highest count\n",
        "print('After converting: \\n',data['class'].value_counts() )\n",
        "\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before converting: \n",
            " 2    283301\n",
            "1    211840\n",
            "3     35754\n",
            "7     20510\n",
            "6     17367\n",
            "5      9493\n",
            "4      2747\n",
            "Name: class, dtype: int64\n",
            "After converting: \n",
            " 0    297711\n",
            "1    283301\n",
            "Name: class, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rq6HM2n5yNi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "outputId": "50af272b-4551-423a-c42e-b42e0f647c1b"
      },
      "source": [
        "#Use a features selection technique to select those features in\n",
        "#your data that contribute most to the prediction.\n",
        "X = data.iloc[:,:-1]  #independent columns\n",
        "y = data.iloc[:,-1]    #target column i.e class range\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "model = ExtraTreesClassifier()\n",
        "model.fit(X,y)\n",
        "print(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n",
        "#plot graph of feature importances for better visualization\n",
        "feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
        "feat_importances.nlargest(10).plot(kind='barh')\n",
        "plt.show()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2.05824301e-01 5.30997471e-02 3.77648199e-02 6.62106227e-02\n",
            " 6.11413466e-02 1.16624140e-01 4.34089115e-02 4.72540284e-02\n",
            " 4.37193148e-02 1.06332995e-01 8.15060799e-03 4.62231231e-03\n",
            " 8.80177664e-03 2.88805573e-02 6.88191980e-04 5.83323925e-03\n",
            " 8.11963594e-04 5.90630369e-03 1.32287343e-04 1.31222978e-03\n",
            " 7.79406525e-05 7.32141242e-05 4.88855153e-04 3.35747690e-03\n",
            " 4.09853114e-03 2.60282834e-02 7.07104781e-03 2.86534746e-04\n",
            " 9.60669844e-08 1.09472928e-03 1.13524981e-03 1.04826298e-03\n",
            " 1.30021873e-03 2.60261186e-03 1.08728939e-03 1.44431732e-02\n",
            " 9.65166738e-03 4.39292906e-03 4.52529664e-04 1.48583002e-03\n",
            " 9.95776748e-04 7.20698292e-04 1.08476036e-02 5.32097284e-03\n",
            " 3.85395702e-03 5.44895091e-03 4.70782484e-03 1.44910032e-03\n",
            " 1.50511770e-03 7.33140312e-05 1.63516376e-04 1.62494326e-02\n",
            " 1.44456435e-02 7.52192219e-03]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnjIECPq_vVO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2e652f9-3712-4f08-fdab-a9f8b3b703a4"
      },
      "source": [
        "feat_importances.nlargest(10).index"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Elevation', 'Horizontal_Distance_To_Roadways',\n",
              "       'Horizontal_Distance_To_Fire_Points',\n",
              "       'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology',\n",
              "       'Aspect', 'Hillshade_Noon', 'Hillshade_3pm', 'Hillshade_9am', 'Slope'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlNenHPTOeFA"
      },
      "source": [
        "***I used 10 of features for X***\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiVK-7Ds5yNv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66f9ce85-e28a-498d-aa8c-31013f570540"
      },
      "source": [
        "#--------------------------------\n",
        "\n",
        "### Use a features selection technique to select those features in\n",
        "# your data that contribute most to the prediction\n",
        "# Divide your dataset into training, validation and testing\n",
        "# datasets.\n",
        "X = data.drop(['class'],axis=1)[feat_importances.nlargest(10).index]\n",
        "Y = data['class']\n",
        "print('X shape after top 10 feature selection : ', X.shape)\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split( X, Y, test_size=0.2,random_state=0)\n",
        "print(\"Number of instances in the training dataset = %d\" % len(X_train))\n",
        "print(\"Number of instances in the test dataset = %d\" % len(X_test))\n",
        "X_train, X_validation, Y_train, Y_validation = train_test_split( X_train, Y_train, test_size=0.3,random_state=0)\n",
        "print(\"Number of instances in the training dataset = %d\" % len(X_train))\n",
        "print(\"Number of instances in the validation dataset = %d\" % len(X_validation))\n",
        "print(\"Number of instances in the test dataset = %d\" % len(X_test))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape after top 10 feature selection :  (581012, 10)\n",
            "Number of instances in the training dataset = 464809\n",
            "Number of instances in the test dataset = 116203\n",
            "Number of instances in the training dataset = 325366\n",
            "Number of instances in the validation dataset = 139443\n",
            "Number of instances in the test dataset = 116203\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUMq0rnbBa5W"
      },
      "source": [
        "# Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4i06uVL5yN3"
      },
      "source": [
        "tree_depth = list(range(1,20))\n",
        "depth_training_acc_list =[]\n",
        "depth_test_acc_list =[]\n",
        "depth_validation_acc_list = []\n",
        "dtc = []"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFcsOaLr_F6e"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        " **DecisionTreeClassifier**```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRIp0TGf5yN-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74944e9a-8af5-4781-8799-ac1e6526adbf"
      },
      "source": [
        "for i in tree_depth:\n",
        "    clf = DecisionTreeClassifier(max_depth = i ,  random_state = 0)\n",
        "    clf.fit(X_train, Y_train)\n",
        "    dtc.append(clf)\n",
        "\n",
        "\n",
        "    predicted_Y_train = clf.predict(X_train)\n",
        "    train_accuracy = accuracy_score(predicted_Y_train, Y_train)\n",
        "    print(\"train_accuracy  \",train_accuracy)\n",
        "   \n",
        "    predicted_Y_validation = clf.predict(X_validation)\n",
        "    validation_accuracy = accuracy_score(predicted_Y_validation, Y_validation)\n",
        "    print(\"validation_accuracy  \",validation_accuracy)\n",
        "    \n",
        "    predicted_Y_test =clf.predict(X_test)\n",
        "    test_accuracy = accuracy_score(predicted_Y_test, Y_test)\n",
        "    print(\"test_accuracy\",test_accuracy)\n",
        "    print('#'*25)\n",
        "    \n",
        "    \n",
        "    validation_result = [i,validation_accuracy]\n",
        "    testing_result = [i,test_accuracy]\n",
        "    train_result = [i,train_accuracy]\n",
        "    depth_training_acc_list.append(train_result)\n",
        "    depth_test_acc_list.append(testing_result)\n",
        "    depth_validation_acc_list.append(validation_result)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_accuracy   0.6684595194334995\n",
            "validation_accuracy   0.6647734199637128\n",
            "test_accuracy 0.6671256335894943\n",
            "#########################\n",
            "train_accuracy   0.7298642144538765\n",
            "validation_accuracy   0.7265907933707679\n",
            "test_accuracy 0.728767759868506\n",
            "#########################\n",
            "train_accuracy   0.7298642144538765\n",
            "validation_accuracy   0.7265907933707679\n",
            "test_accuracy 0.728767759868506\n",
            "#########################\n",
            "train_accuracy   0.7398068636550839\n",
            "validation_accuracy   0.7387462977704151\n",
            "test_accuracy 0.7383630370988701\n",
            "#########################\n",
            "train_accuracy   0.7459384201176521\n",
            "validation_accuracy   0.7430061028520614\n",
            "test_accuracy 0.7437587669853618\n",
            "#########################\n",
            "train_accuracy   0.7545103053177038\n",
            "validation_accuracy   0.7520492244142768\n",
            "test_accuracy 0.7529151570957721\n",
            "#########################\n",
            "train_accuracy   0.7693428323795357\n",
            "validation_accuracy   0.765911519402193\n",
            "test_accuracy 0.7671918969389775\n",
            "#########################\n",
            "train_accuracy   0.7763718397128158\n",
            "validation_accuracy   0.771849429516003\n",
            "test_accuracy 0.7747820624252386\n",
            "#########################\n",
            "train_accuracy   0.7914348764160976\n",
            "validation_accuracy   0.7850662994915485\n",
            "test_accuracy 0.7863910570295087\n",
            "#########################\n",
            "train_accuracy   0.8025853961385024\n",
            "validation_accuracy   0.7949341307917931\n",
            "test_accuracy 0.7959002779618426\n",
            "#########################\n",
            "train_accuracy   0.8147163502025412\n",
            "validation_accuracy   0.8050673034860122\n",
            "test_accuracy 0.8070875967057649\n",
            "#########################\n",
            "train_accuracy   0.8303387569690748\n",
            "validation_accuracy   0.8171582653844223\n",
            "test_accuracy 0.8189633658339286\n",
            "#########################\n",
            "train_accuracy   0.844230804693791\n",
            "validation_accuracy   0.826481071118665\n",
            "test_accuracy 0.8276464463051728\n",
            "#########################\n",
            "train_accuracy   0.8609166292728804\n",
            "validation_accuracy   0.8382708346779688\n",
            "test_accuracy 0.8406925810865468\n",
            "#########################\n",
            "train_accuracy   0.8778790654217097\n",
            "validation_accuracy   0.850469367411774\n",
            "test_accuracy 0.8519659561284992\n",
            "#########################\n",
            "train_accuracy   0.8933170644750834\n",
            "validation_accuracy   0.8619005615197608\n",
            "test_accuracy 0.863901964665284\n",
            "#########################\n",
            "train_accuracy   0.9089886466317931\n",
            "validation_accuracy   0.8712018530869244\n",
            "test_accuracy 0.8724559606894831\n",
            "#########################\n",
            "train_accuracy   0.9219770965620255\n",
            "validation_accuracy   0.8796354065819009\n",
            "test_accuracy 0.8806571258917584\n",
            "#########################\n",
            "train_accuracy   0.9351222930484439\n",
            "validation_accuracy   0.8867422531070043\n",
            "test_accuracy 0.8870597144652032\n",
            "#########################\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLEouT-N5yOG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92410705-3f35-4ab1-8807-135910f42bb6"
      },
      "source": [
        "i=0\n",
        "while (i < len(depth_training_acc_list)):\n",
        "    temp_list = depth_training_acc_list[i]\n",
        "    tree_size = temp_list[0]\n",
        "    training_acc = temp_list[1]\n",
        "    \n",
        "    temp_list = depth_test_acc_list[i]\n",
        "    test_acc = temp_list[1]\n",
        "\n",
        "    val_acc = depth_validation_acc_list[i][1]\n",
        "    print(\"tree szie :%d \\t training accuracy:%f \\t validation accuracy:%f \\t test accuracy:%f\" % (tree_size, training_acc, val_acc, test_acc))\n",
        "    i= i+1"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tree szie :1 \t training accuracy:0.668460 \t validation accuracy:0.664773 \t test accuracy:0.667126\n",
            "tree szie :2 \t training accuracy:0.729864 \t validation accuracy:0.726591 \t test accuracy:0.728768\n",
            "tree szie :3 \t training accuracy:0.729864 \t validation accuracy:0.726591 \t test accuracy:0.728768\n",
            "tree szie :4 \t training accuracy:0.739807 \t validation accuracy:0.738746 \t test accuracy:0.738363\n",
            "tree szie :5 \t training accuracy:0.745938 \t validation accuracy:0.743006 \t test accuracy:0.743759\n",
            "tree szie :6 \t training accuracy:0.754510 \t validation accuracy:0.752049 \t test accuracy:0.752915\n",
            "tree szie :7 \t training accuracy:0.769343 \t validation accuracy:0.765912 \t test accuracy:0.767192\n",
            "tree szie :8 \t training accuracy:0.776372 \t validation accuracy:0.771849 \t test accuracy:0.774782\n",
            "tree szie :9 \t training accuracy:0.791435 \t validation accuracy:0.785066 \t test accuracy:0.786391\n",
            "tree szie :10 \t training accuracy:0.802585 \t validation accuracy:0.794934 \t test accuracy:0.795900\n",
            "tree szie :11 \t training accuracy:0.814716 \t validation accuracy:0.805067 \t test accuracy:0.807088\n",
            "tree szie :12 \t training accuracy:0.830339 \t validation accuracy:0.817158 \t test accuracy:0.818963\n",
            "tree szie :13 \t training accuracy:0.844231 \t validation accuracy:0.826481 \t test accuracy:0.827646\n",
            "tree szie :14 \t training accuracy:0.860917 \t validation accuracy:0.838271 \t test accuracy:0.840693\n",
            "tree szie :15 \t training accuracy:0.877879 \t validation accuracy:0.850469 \t test accuracy:0.851966\n",
            "tree szie :16 \t training accuracy:0.893317 \t validation accuracy:0.861901 \t test accuracy:0.863902\n",
            "tree szie :17 \t training accuracy:0.908989 \t validation accuracy:0.871202 \t test accuracy:0.872456\n",
            "tree szie :18 \t training accuracy:0.921977 \t validation accuracy:0.879635 \t test accuracy:0.880657\n",
            "tree szie :19 \t training accuracy:0.935122 \t validation accuracy:0.886742 \t test accuracy:0.887060\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbs5gdxhT7Af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d7746df-43cc-4a37-914f-c7091e1c504b"
      },
      "source": [
        "# Selection of best model\n",
        "clf = dtc[15] # treesize = 16\n",
        "predicted_Y_train = clf.predict(X_train)\n",
        "train_accuracy = accuracy_score(predicted_Y_train, Y_train)\n",
        "print(\"train_accuracy  \",train_accuracy)\n",
        "\n",
        "predicted_Y_validation = clf.predict(X_validation)\n",
        "validation_accuracy = accuracy_score(predicted_Y_validation, Y_validation)\n",
        "print(\"validation_accuracy  \",validation_accuracy)\n",
        "\n",
        "predicted_Y_test =clf.predict(X_test)\n",
        "test_accuracy = accuracy_score(predicted_Y_test, Y_test)\n",
        "print(\"test_accuracy\",test_accuracy)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_accuracy   0.8933170644750834\n",
            "validation_accuracy   0.8619005615197608\n",
            "test_accuracy 0.863901964665284\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgjqX-9h5yOO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b426799-c886-4a6c-cfe0-2dcc13f80f09"
      },
      "source": [
        "print(\"confusion matrix for validation data set\",'\\n')\n",
        "\n",
        "cm = confusion_matrix(Y_validation,predicted_Y_validation)\n",
        "\n",
        "print('Confusion matrix\\n\\n', cm)\n",
        "\n",
        "print('\\nTrue Positives(TP) = ', cm[0,0])\n",
        "\n",
        "print('\\nTrue Negatives(TN) = ', cm[1,1])\n",
        "\n",
        "print('\\nFalse Positives(FP) = ', cm[0,1])\n",
        "\n",
        "print('\\nFalse Negatives(FN) = ', cm[1,0])\n",
        "\n",
        "#Classification accuracy\n",
        "TP = cm[0,0]\n",
        "TN = cm[1,1]\n",
        "FP = cm[0,1]\n",
        "FN = cm[1,0]\n",
        "# print classification accuracy\n",
        "\n",
        "classification_accuracy = (TP + TN) / float(TP + TN + FP + FN)\n",
        "\n",
        "print('\\n','Classification accuracy  for validation data set : {0:0.4f}'.format(classification_accuracy),'\\n')\n",
        "\n",
        "#Classification error\n",
        "# print classification error\n",
        "\n",
        "classification_error = (FP + FN) / float(TP + TN + FP + FN)\n",
        "\n",
        "print('\\n','Classification error  for validation data set : {0:0.4f}'.format(classification_error),'\\n')\n",
        "\n",
        "\n",
        "#Precision It is the Exactness, \n",
        "Precision = TP/(TP+FP) \n",
        "print('\\n',\"Precision for validation data set {:0.2f}\".format(Precision),'\\n')\n",
        "\n",
        "#Recall It is the Completeness,\n",
        "\n",
        "Recall = TP/(TP+FN) \n",
        "print('\\n',\"Recall for validation data set {:0.2f}\".format(Recall),'\\n')\n",
        "\n",
        "#F-Measure Harmonic mean of Precision & Recall,\n",
        "#used to indicate a balance between Precision & Recall providing each equal weightage\n",
        "\n",
        "f1 = (2*Precision*Recall)/(Precision + Recall)\n",
        "print(\"F-Measure for validation data set  {:0.2f}\".format(f1))\n",
        "\n",
        "print('\\n',\"confusion matrix for testing data set\",'\\n')\n",
        "\n",
        "\n",
        "cm = confusion_matrix(Y_test,predicted_Y_test)\n",
        "\n",
        "print('Confusion matrix\\n\\n', cm)\n",
        "\n",
        "print('\\nTrue Positives(TP) = ', cm[0,0])\n",
        "\n",
        "print('\\nTrue Negatives(TN) = ', cm[1,1])\n",
        "\n",
        "print('\\nFalse Positives(FP) = ', cm[0,1])\n",
        "\n",
        "print('\\nFalse Negatives(FN) = ', cm[1,0])\n",
        "#Classification accuracy\n",
        "TP = cm[0,0]\n",
        "TN = cm[1,1]\n",
        "FP = cm[0,1]\n",
        "FN = cm[1,0]\n",
        "# print classification accuracy\n",
        "\n",
        "classification_accuracy = (TP + TN) / float(TP + TN + FP + FN)\n",
        "\n",
        "print('\\n','Classification accuracy for testing data set : {0:0.4f}'.format(classification_accuracy),'\\n')\n",
        "\n",
        "#Classification error\n",
        "# print classification error\n",
        "\n",
        "classification_error = (FP + FN) / float(TP + TN + FP + FN)\n",
        "\n",
        "print('\\n','Classification error  for testing data set : {0:0.4f}'.format(classification_error),'\\n')\n",
        "\n",
        "#Precision It is the Exactness, \n",
        "Precision = TP/(TP+FP) \n",
        "print('\\n',\"Precision for testing data set {:0.2f}\".format(Precision),'\\n')\n",
        "\n",
        "#Recall It is the Completeness,\n",
        "\n",
        "Recall = TP/(TP+FN) \n",
        "print('\\n',\"Recall for testing data set {:0.2f}\".format(Recall),'\\n')\n",
        "\n",
        "#F-Measure Harmonic mean of Precision & Recall,\n",
        "#used to indicate a balance between Precision & Recall providing each equal weightage\n",
        "\n",
        "f1 = (2*Precision*Recall)/(Precision + Recall)\n",
        "print(\"F-Measure for testing data set  {:0.2f}\".format(f1))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "confusion matrix for validation data set \n",
            "\n",
            "Confusion matrix\n",
            "\n",
            " [[59585 12256]\n",
            " [ 7001 60601]]\n",
            "\n",
            "True Positives(TP) =  59585\n",
            "\n",
            "True Negatives(TN) =  60601\n",
            "\n",
            "False Positives(FP) =  12256\n",
            "\n",
            "False Negatives(FN) =  7001\n",
            "\n",
            " Classification accuracy  for validation data set : 0.8619 \n",
            "\n",
            "\n",
            " Classification error  for validation data set : 0.1381 \n",
            "\n",
            "\n",
            " Precision for validation data set 0.83 \n",
            "\n",
            "\n",
            " Recall for validation data set 0.89 \n",
            "\n",
            "F-Measure for validation data set  0.86\n",
            "\n",
            " confusion matrix for testing data set \n",
            "\n",
            "Confusion matrix\n",
            "\n",
            " [[49345 10009]\n",
            " [ 5806 51043]]\n",
            "\n",
            "True Positives(TP) =  49345\n",
            "\n",
            "True Negatives(TN) =  51043\n",
            "\n",
            "False Positives(FP) =  10009\n",
            "\n",
            "False Negatives(FN) =  5806\n",
            "\n",
            " Classification accuracy for testing data set : 0.8639 \n",
            "\n",
            "\n",
            " Classification error  for testing data set : 0.1361 \n",
            "\n",
            "\n",
            " Precision for testing data set 0.83 \n",
            "\n",
            "\n",
            " Recall for testing data set 0.89 \n",
            "\n",
            "F-Measure for testing data set  0.86\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziGEDMYQ5yOV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf8cdd19-031a-4808-8622-253431228c90"
      },
      "source": [
        "# train a Gaussian Naive Bayes classifier \n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "\n",
        "# instantiate the model\n",
        "gnb = GaussianNB()\n",
        "\n",
        "\n",
        "# fit the model\n",
        "gnb.fit(X_train, Y_train)\n",
        "\n",
        "predicted_Y_validation = gnb.predict(X_validation)\n",
        "\n",
        "validation_accuracy = accuracy_score(predicted_Y_validation, Y_validation)\n",
        "print(\"validation_accuracy  \",validation_accuracy)\n",
        "\n",
        "\n",
        "predicted_Y_test =gnb.predict(X_test)\n",
        "test_accuracy = accuracy_score(predicted_Y_test, Y_test)\n",
        "print(\"test_accuracy\",test_accuracy)\n",
        "   \n",
        "    \n"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation_accuracy   0.6533780828008577\n",
            "test_accuracy 0.6555424558746332\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3E_2IGx5yOe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f795f34f-c01d-45de-d2b5-54fab751baab"
      },
      "source": [
        "print(\"confusion matrix for validation data set\",'\\n')\n",
        "\n",
        "cm = confusion_matrix(Y_validation,predicted_Y_validation)\n",
        "\n",
        "print('Confusion matrix\\n\\n', cm)\n",
        "\n",
        "print('\\nTrue Positives(TP) = ', cm[0,0])\n",
        "\n",
        "print('\\nTrue Negatives(TN) = ', cm[1,1])\n",
        "\n",
        "print('\\nFalse Positives(FP) = ', cm[0,1])\n",
        "\n",
        "print('\\nFalse Negatives(FN) = ', cm[1,0])\n",
        "#Classification accuracy\n",
        "TP = cm[0,0]\n",
        "TN = cm[1,1]\n",
        "FP = cm[0,1]\n",
        "FN = cm[1,0]\n",
        "# print classification accuracy\n",
        "\n",
        "classification_accuracy = (TP + TN) / float(TP + TN + FP + FN)\n",
        "\n",
        "print('\\n','Classification accuracy  for validation data set : {0:0.4f}'.format(classification_accuracy),'\\n')\n",
        "#Classification error\n",
        "# print classification error\n",
        "\n",
        "classification_error = (FP + FN) / float(TP + TN + FP + FN)\n",
        "\n",
        "print('\\n','Classification error  for validation data set : {0:0.4f}'.format(classification_error),'\\n')\n",
        "\n",
        "#Precision It is the Exactness, \n",
        "Precision = TP/(TP+FP) \n",
        "print('\\n',\"Precision for validation data set {:0.2f}\".format(Precision),'\\n')\n",
        "\n",
        "#Recall It is the Completeness,\n",
        "\n",
        "Recall = TP/(TP+FN) \n",
        "print('\\n',\"Recall for validation data set {:0.2f}\".format(Recall),'\\n')\n",
        "\n",
        "#F-Measure Harmonic mean of Precision & Recall,\n",
        "#used to indicate a balance between Precision & Recall providing each equal weightage\n",
        "\n",
        "f1 = (2*Precision*Recall)/(Precision + Recall)\n",
        "print(\"F-Measure for validation data set  {:0.2f}\".format(f1))\n",
        "\n",
        "\n",
        "print('\\n',\"confusion matrix for testing data set\",'\\n')\n",
        "\n",
        "cm = confusion_matrix(Y_test,predicted_Y_test)\n",
        "\n",
        "print('Confusion matrix\\n\\n', cm)\n",
        "\n",
        "print('\\nTrue Positives(TP) = ', cm[0,0])\n",
        "\n",
        "print('\\nTrue Negatives(TN) = ', cm[1,1])\n",
        "\n",
        "print('\\nFalse Positives(FP) = ', cm[0,1])\n",
        "\n",
        "print('\\nFalse Negatives(FN) = ', cm[1,0])\n",
        "#Classification accuracy\n",
        "TP = cm[0,0]\n",
        "TN = cm[1,1]\n",
        "FP = cm[0,1]\n",
        "FN = cm[1,0]\n",
        "# print classification accuracy\n",
        "\n",
        "classification_accuracy = (TP + TN) / float(TP + TN + FP + FN)\n",
        "\n",
        "print('\\n','Classification accuracy for testing data set : {0:0.4f}'.format(classification_accuracy),'\\n')\n",
        "#Classification error\n",
        "# print classification error\n",
        "\n",
        "classification_error = (FP + FN) / float(TP + TN + FP + FN)\n",
        "\n",
        "print('\\n','Classification error  for testing data set : {0:0.4f}'.format(classification_error),'\\n')\n",
        "\n",
        "#Precision It is the Exactness, \n",
        "Precision = TP/(TP+FP) \n",
        "print('\\n',\"Precision for testing data set {:0.2f}\".format(Precision),'\\n')\n",
        "\n",
        "#Recall It is the Completeness,\n",
        "\n",
        "Recall = TP/(TP+FN) \n",
        "print('\\n',\"Recall for testing data set {:0.2f}\".format(Recall),'\\n')\n",
        "\n",
        "#F-Measure Harmonic mean of Precision & Recall,\n",
        "#used to indicate a balance between Precision & Recall providing each equal weightage\n",
        "\n",
        "f1 = (2*Precision*Recall)/(Precision + Recall)\n",
        "print(\"F-Measure for testing data set  {:0.2f}\".format(f1))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "confusion matrix for validation data set \n",
            "\n",
            "Confusion matrix\n",
            "\n",
            " [[43990 27851]\n",
            " [20483 47119]]\n",
            "\n",
            "True Positives(TP) =  43990\n",
            "\n",
            "True Negatives(TN) =  47119\n",
            "\n",
            "False Positives(FP) =  27851\n",
            "\n",
            "False Negatives(FN) =  20483\n",
            "\n",
            " Classification accuracy  for validation data set : 0.6534 \n",
            "\n",
            "\n",
            " Classification error  for validation data set : 0.3466 \n",
            "\n",
            "\n",
            " Precision for validation data set 0.61 \n",
            "\n",
            "\n",
            " Recall for validation data set 0.68 \n",
            "\n",
            "F-Measure for validation data set  0.65\n",
            "\n",
            " confusion matrix for testing data set \n",
            "\n",
            "Confusion matrix\n",
            "\n",
            " [[36504 22850]\n",
            " [17177 39672]]\n",
            "\n",
            "True Positives(TP) =  36504\n",
            "\n",
            "True Negatives(TN) =  39672\n",
            "\n",
            "False Positives(FP) =  22850\n",
            "\n",
            "False Negatives(FN) =  17177\n",
            "\n",
            " Classification accuracy for testing data set : 0.6555 \n",
            "\n",
            "\n",
            " Classification error  for testing data set : 0.3445 \n",
            "\n",
            "\n",
            " Precision for testing data set 0.62 \n",
            "\n",
            "\n",
            " Recall for testing data set 0.68 \n",
            "\n",
            "F-Measure for testing data set  0.65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_dlT3Fa5yOk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "987fe632-2d25-4d1e-fd26-d80be9977bd3"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "tree_num = list(range(1,10))\n",
        "depth_traing_acc_list =[]\n",
        "depth_test_acc_list =[]\n",
        "depth_validation_acc_list = []\n",
        "rfc = []\n",
        "\n",
        "\n",
        "\n",
        "print(\"Number of instances in the training dataset = %d\" % len(X_train))\n",
        "print(\"Number of instances in the test dataset = %d\" % len(X_test))\n",
        "\n",
        "print(\"Number of instances in the training dataset = %d\" % len(X_train))\n",
        "print(\"Number of instances in the validation dataset = %d\" % len(X_validation))\n",
        "print(\"Number of instances in the test dataset = %d\" % len(X_test))\n",
        "for i in tree_num:\n",
        "    print('Number of estimators used: ', 10+i*3)\n",
        "    # train a Random Forest Classifier \n",
        "    # n_estimator means that this number of decision tress would be trained to ensemble into a random forest\n",
        "    clf2 = RandomForestClassifier( random_state=0, n_estimators = 10+ i*3)\n",
        "    clf2.fit(X_train, Y_train)\n",
        "    rfc.append(clf2)\n",
        "\n",
        "    predicted_Y_train = clf2.predict(X_train)\n",
        "    train_accuracy = accuracy_score(predicted_Y_train, Y_train)\n",
        "    print(\"train_accuracy  \",train_accuracy)\n",
        "   \n",
        "    predicted_Y_validation = clf2.predict(X_validation)\n",
        "    validation_accuracy = accuracy_score(predicted_Y_validation, Y_validation)\n",
        "    print(\"validation_accuracy  \",validation_accuracy)\n",
        "    \n",
        "    predicted_Y_test =clf2.predict(X_test)\n",
        "    test_accuracy = accuracy_score(predicted_Y_test, Y_test)\n",
        "    print(\"test_accuracy\",test_accuracy)\n",
        "    print('#'*25)\n",
        "    \n",
        "    \n",
        "    validation_result = [i,validation_accuracy]\n",
        "    testing_result = [i,test_accuracy]\n",
        "    train_result = [i,train_accuracy]\n",
        "    depth_training_acc_list.append(train_result)\n",
        "    depth_test_acc_list.append(testing_result)\n",
        "    depth_validation_acc_list.append(validation_result)\n",
        "\n",
        "    ###################\n",
        "    "
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of instances in the training dataset = 325366\n",
            "Number of instances in the test dataset = 116203\n",
            "Number of instances in the training dataset = 325366\n",
            "Number of instances in the validation dataset = 139443\n",
            "Number of instances in the test dataset = 116203\n",
            "Number of estimators used:  13\n",
            "train_accuracy   0.9988781864116103\n",
            "validation_accuracy   0.9370782326828884\n",
            "test_accuracy 0.9380480710480796\n",
            "#########################\n",
            "Number of estimators used:  16\n",
            "train_accuracy   0.9993576464658261\n",
            "validation_accuracy   0.9391292499444217\n",
            "test_accuracy 0.9400101546431675\n",
            "#########################\n",
            "Number of estimators used:  19\n",
            "train_accuracy   0.9995482011027581\n",
            "validation_accuracy   0.9405133280265054\n",
            "test_accuracy 0.9416538299355438\n",
            "#########################\n",
            "Number of estimators used:  22\n",
            "train_accuracy   0.9996465518831101\n",
            "validation_accuracy   0.9414384372109034\n",
            "test_accuracy 0.9434954347133895\n",
            "#########################\n",
            "Number of estimators used:  25\n",
            "train_accuracy   0.9997787107442081\n",
            "validation_accuracy   0.9424065747294593\n",
            "test_accuracy 0.9445711384387666\n",
            "#########################\n",
            "Number of estimators used:  28\n",
            "train_accuracy   0.9998494003675861\n",
            "validation_accuracy   0.9435181400285422\n",
            "test_accuracy 0.9454833351978864\n",
            "#########################\n",
            "Number of estimators used:  31\n",
            "train_accuracy   0.999895502295876\n",
            "validation_accuracy   0.9439125664249909\n",
            "test_accuracy 0.9458964054284312\n",
            "#########################\n",
            "Number of estimators used:  34\n",
            "train_accuracy   0.9999016492196481\n",
            "validation_accuracy   0.9443069928214396\n",
            "test_accuracy 0.946232024990749\n",
            "#########################\n",
            "Number of estimators used:  37\n",
            "train_accuracy   0.999941604224166\n",
            "validation_accuracy   0.9441492222628601\n",
            "test_accuracy 0.946266447509961\n",
            "#########################\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3v3C5lGUgJb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "589cee82-f19c-444c-ab7f-b739f88ae70b"
      },
      "source": [
        "clf2 = rfc[1] # As overfitting is least\n",
        "predicted_Y_train = clf2.predict(X_train)\n",
        "train_accuracy = accuracy_score(predicted_Y_train, Y_train)\n",
        "print(\"train_accuracy  \",train_accuracy)\n",
        "\n",
        "predicted_Y_validation = clf2.predict(X_validation)\n",
        "validation_accuracy = accuracy_score(predicted_Y_validation, Y_validation)\n",
        "print(\"validation_accuracy  \",validation_accuracy)\n",
        "\n",
        "predicted_Y_test =clf2.predict(X_test)\n",
        "test_accuracy = accuracy_score(predicted_Y_test, Y_test)\n",
        "print(\"test_accuracy\",test_accuracy)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_accuracy   0.9993576464658261\n",
            "validation_accuracy   0.9391292499444217\n",
            "test_accuracy 0.9400101546431675\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFmBF9_g5yOs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d780860-fe1d-4634-c2b2-e23e4e32a1f6"
      },
      "source": [
        "print(\"confusion matrix for validation data set\",'\\n')\n",
        "\n",
        "cm = confusion_matrix(Y_validation,predicted_Y_validation)\n",
        "\n",
        "print('Confusion matrix\\n\\n', cm)\n",
        "\n",
        "print('\\nTrue Positives(TP) = ', cm[0,0])\n",
        "\n",
        "print('\\nTrue Negatives(TN) = ', cm[1,1])\n",
        "\n",
        "print('\\nFalse Positives(FP) = ', cm[0,1])\n",
        "\n",
        "print('\\nFalse Negatives(FN) = ', cm[1,0])\n",
        "#Classification accuracy\n",
        "TP = cm[0,0]\n",
        "TN = cm[1,1]\n",
        "FP = cm[0,1]\n",
        "FN = cm[1,0]\n",
        "# print classification accuracy\n",
        "\n",
        "classification_accuracy = (TP + TN) / float(TP + TN + FP + FN)\n",
        "\n",
        "print('\\n','Classification accuracy  for validation data set : {0:0.4f}'.format(classification_accuracy),'\\n')\n",
        "#Classification error\n",
        "# print classification error\n",
        "\n",
        "classification_error = (FP + FN) / float(TP + TN + FP + FN)\n",
        "\n",
        "print('\\n','Classification error  for validation data set : {0:0.4f}'.format(classification_error),'\\n')\n",
        "\n",
        "#Precision It is the Exactness, \n",
        "Precision = TP/(TP+FP) \n",
        "print('\\n',\"Precision for validation data set {:0.2f}\".format(Precision),'\\n')\n",
        "\n",
        "#Recall It is the Completeness,\n",
        "\n",
        "Recall = TP/(TP+FN) \n",
        "print('\\n',\"Recall for validation data set {:0.2f}\".format(Recall),'\\n')\n",
        "\n",
        "#F-Measure Harmonic mean of Precision & Recall,\n",
        "#used to indicate a balance between Precision & Recall providing each equal weightage\n",
        "\n",
        "f1 = (2*Precision*Recall)/(Precision + Recall)\n",
        "print(\"F-Measure for validation data set  {:0.2f}\".format(f1))\n",
        "\n",
        "\n",
        "print('\\n',\"confusion matrix for testing data set\",'\\n')\n",
        "\n",
        "cm = confusion_matrix(Y_test,predicted_Y_test)\n",
        "\n",
        "print('Confusion matrix\\n\\n', cm)\n",
        "\n",
        "print('\\nTrue Positives(TP) = ', cm[0,0])\n",
        "\n",
        "print('\\nTrue Negatives(TN) = ', cm[1,1])\n",
        "\n",
        "print('\\nFalse Positives(FP) = ', cm[0,1])\n",
        "\n",
        "print('\\nFalse Negatives(FN) = ', cm[1,0])\n",
        "#Classification accuracy\n",
        "TP = cm[0,0]\n",
        "TN = cm[1,1]\n",
        "FP = cm[0,1]\n",
        "FN = cm[1,0]\n",
        "# print classification accuracy\n",
        "\n",
        "classification_accuracy = (TP + TN) / float(TP + TN + FP + FN)\n",
        "\n",
        "print('\\n','Classification accuracy for testing data set : {0:0.4f}'.format(classification_accuracy),'\\n')\n",
        "#Classification error\n",
        "# print classification error\n",
        "\n",
        "classification_error = (FP + FN) / float(TP + TN + FP + FN)\n",
        "\n",
        "print('\\n','Classification error  for testing data set : {0:0.4f}'.format(classification_error),'\\n')\n",
        "\n",
        "#Precision It is the Exactness, \n",
        "Precision = TP/(TP+FP) \n",
        "print('\\n',\"Precision for testing data set {:0.2f}\".format(Precision),'\\n')\n",
        "\n",
        "#Recall It is the Completeness,\n",
        "\n",
        "Recall = TP/(TP+FN) \n",
        "print('\\n',\"Recall for testing data set {:0.2f}\".format(Recall),'\\n')\n",
        "\n",
        "#F-Measure Harmonic mean of Precision & Recall,\n",
        "#used to indicate a balance between Precision & Recall providing each equal weightage\n",
        "\n",
        "f1 = (2*Precision*Recall)/(Precision + Recall)\n",
        "print(\"F-Measure for testing data set  {:0.2f}\".format(f1))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "confusion matrix for validation data set \n",
            "\n",
            "Confusion matrix\n",
            "\n",
            " [[67599  4242]\n",
            " [ 4246 63356]]\n",
            "\n",
            "True Positives(TP) =  67599\n",
            "\n",
            "True Negatives(TN) =  63356\n",
            "\n",
            "False Positives(FP) =  4242\n",
            "\n",
            "False Negatives(FN) =  4246\n",
            "\n",
            " Classification accuracy  for validation data set : 0.9391 \n",
            "\n",
            "\n",
            " Classification error  for validation data set : 0.0609 \n",
            "\n",
            "\n",
            " Precision for validation data set 0.94 \n",
            "\n",
            "\n",
            " Recall for validation data set 0.94 \n",
            "\n",
            "F-Measure for validation data set  0.94\n",
            "\n",
            " confusion matrix for testing data set \n",
            "\n",
            "Confusion matrix\n",
            "\n",
            " [[55882  3472]\n",
            " [ 3499 53350]]\n",
            "\n",
            "True Positives(TP) =  55882\n",
            "\n",
            "True Negatives(TN) =  53350\n",
            "\n",
            "False Positives(FP) =  3472\n",
            "\n",
            "False Negatives(FN) =  3499\n",
            "\n",
            " Classification accuracy for testing data set : 0.9400 \n",
            "\n",
            "\n",
            " Classification error  for testing data set : 0.0600 \n",
            "\n",
            "\n",
            " Precision for testing data set 0.94 \n",
            "\n",
            "\n",
            " Recall for testing data set 0.94 \n",
            "\n",
            "F-Measure for testing data set  0.94\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4uOa7qO5yO2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f3ab889-5a53-4d3d-8fad-92ce8a7a1f7c"
      },
      "source": [
        "# Applying 10-Fold Cross Validation\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "# cv = Data is divided into k number of dubsets for comparison\n",
        "scores = cross_val_score(gnb, X_train, Y_train, cv = 5, scoring='accuracy')\n",
        "\n",
        "print('Cross-validation scores for gnp :{}'.format(scores.mean()))\n",
        "\n",
        "scores2 = cross_val_score(clf, X_train, Y_train, cv = 5, scoring='accuracy')\n",
        "\n",
        "print('Cross-validation scores for clf :{}'.format(scores2.mean()))\n",
        "\n",
        "scores3 = cross_val_score(clf2, X_train, Y_train, cv = 5, scoring='accuracy')\n",
        "\n",
        "print('Cross-validation scores for clf2 :{}'.format(scores3.mean()))\n",
        "\n",
        "\n"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation scores for gnp :0.6546904025481888\n",
            "Cross-validation scores for clf :0.8589434644696798\n",
            "Cross-validation scores for clf2 :0.9334349606946521\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0scXGgH5yPD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 787
        },
        "outputId": "e16596ab-1fbe-42ef-fa57-529b4544bdb6"
      },
      "source": [
        "results = []\n",
        "names = []\n",
        "results.append(scores)\n",
        "names.append('gnb')\n",
        "results.append(scores2)\n",
        "names.append('clf')\n",
        "results.append(scores3)\n",
        "names.append('clf2')\n",
        "# boxplot algorithm comparison\n",
        "fig = plt.figure(figsize=(5,12))\n",
        "fig.suptitle('Algorithm Comparison')\n",
        "ax = fig.add_subplot(111)\n",
        "plt.boxplot(results)\n",
        "ax.set_xticklabels(names)\n",
        "\n",
        "# Remove top and right border\n",
        "ax.spines['top'].set_visible(False)\n",
        "ax.spines['right'].set_visible(False)\n",
        "ax.spines['left'].set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x864 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPEqNKcUFNwf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "fe1887ed-d4c6-49f2-cf8e-d4329fa5431e"
      },
      "source": [
        "print(names[0])\n",
        "print(scores.mean())\n",
        "left = [5, 10, 15]\n",
        " \n",
        "# heights of bars\n",
        "height = [scores.mean(), scores2.mean(), scores3.mean()]\n",
        "names = ['Nave Bayes','Decision Tree','Random Forest']\n",
        "plt.bar(left, height, tick_label = names,\n",
        "        width = 0.8, color = ['red', 'green'])\n",
        "# naming the x-axis\n",
        "plt.xlabel('Models Names')\n",
        "# naming the y-axis\n",
        "plt.ylabel('ACC')\n",
        "# plot title\n",
        "plt.title('My comparison')"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nave Bayes\n",
            "0.6546904025481888\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'My comparison')"
            ]
          },
          "metadata": {},
          "execution_count": 73
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}